{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix,load_npz,save_npz\n",
    "from get_feature_dictionary import get_feature_dictionary\n",
    "from feature_selection import feature_wise_importance\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    NOTEBOOK_PATH=os.getcwd()\n",
    "    PROJECT_ROOT=os.path.dirname(NOTEBOOK_PATH)\n",
    "    return PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT=get_path()\n",
    "OUTPUT_PATH_TRAIN=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"train\")\n",
    "OUTPUT_PATH_TEST=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"test\")\n",
    "OUTPUT_PATH_CV=os.path.join(PROJECT_ROOT,\"data\",\"processed\",\"cv\")\n",
    "MODEL_PATH=os.path.join(PROJECT_ROOT,\"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dictionary=get_feature_dictionary(PROJECT_ROOT)\n",
    "feature_dictionary=np.array(feature_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    print(\"Number of misclassified points \",(len(test_y)-np.trace(C))/len(test_y)*100)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    \n",
    "    labels = [1,2,3,4,5,6,7,8,9]\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME=\"all_features_normalized.npz\"\n",
    "X_train=load_npz(os.path.join(OUTPUT_PATH_TRAIN,FILE_NAME))\n",
    "X_test=load_npz(os.path.join(OUTPUT_PATH_TEST,FILE_NAME))\n",
    "X_cv=load_npz(os.path.join(OUTPUT_PATH_CV,FILE_NAME))\n",
    "\n",
    "FILE_NAME=\"y_train.csv\"\n",
    "y_train=pd.read_csv(os.path.join(OUTPUT_PATH_TRAIN,FILE_NAME))\n",
    "FILE_NAME=\"y_test.csv\"\n",
    "y_test=pd.read_csv(os.path.join(OUTPUT_PATH_TEST,FILE_NAME))\n",
    "FILE_NAME=\"y_cv.csv\"\n",
    "y_cv=pd.read_csv(os.path.join(OUTPUT_PATH_CV,FILE_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=feature_wise_importance(X,y_train,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find more about KNeighborsClassifier() here http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "# -------------------------\n",
    "# default parameter\n",
    "# KNeighborsClassifier(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, \n",
    "# metric=’minkowski’, metric_params=None, n_jobs=1, **kwargs)\n",
    "\n",
    "# methods of\n",
    "# fit(X, y) : Fit the model using X as training data and y as target values\n",
    "# predict(X):Predict the class labels for the provided data\n",
    "# predict_proba(X):Return probability estimates for the test data X.\n",
    "#-------------------------------------\n",
    "# video link: https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/k-nearest-neighbors-geometric-intuition-with-a-toy-example-1/\n",
    "#-------------------------------------\n",
    "\n",
    "\n",
    "# find more about CalibratedClassifierCV here at http://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html\n",
    "# ----------------------------\n",
    "# default paramters\n",
    "# sklearn.calibration.CalibratedClassifierCV(base_estimator=None, method=’sigmoid’, cv=3)\n",
    "#\n",
    "# some of the methods of CalibratedClassifierCV()\n",
    "# fit(X, y[, sample_weight])\tFit the calibrated model\n",
    "# get_params([deep])\tGet parameters for this estimator.\n",
    "# predict(X)\tPredict the target of new samples.\n",
    "# predict_proba(X)\tPosterior probabilities of classification\n",
    "#-------------------------------------\n",
    "# video link:\n",
    "#-------------------------------------\n",
    "  \n",
    "alpha = [x for x in range(1, 15, 2)]\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    k_cfl=KNeighborsClassifier(n_neighbors=i)\n",
    "    k_cfl.fit(X_train,y_train)\n",
    "    sig_clf = CalibratedClassifierCV(k_cfl, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_cv)\n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=k_cfl.classes_, eps=1e-15))\n",
    "    \n",
    "for i in range(len(cv_log_error_array)):\n",
    "    print ('log_loss for k = ',alpha[i],'is',cv_log_error_array[i])\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "k_cfl=KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "k_cfl.fit(X_train,y_train)\n",
    "sig_clf = CalibratedClassifierCV(k_cfl, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "    \n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print ('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y))\n",
    "predict_y = sig_clf.predict_proba(X_cv)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y))\n",
    "plot_confusion_matrix(y_test, sig_clf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
